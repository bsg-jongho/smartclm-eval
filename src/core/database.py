import asyncio
import logging
from typing import AsyncGenerator, List, Type

from sqlalchemy.ext.asyncio import async_sessionmaker, create_async_engine
from sqlmodel import SQLModel, text
from sqlmodel.ext.asyncio.session import AsyncSession

from src.core.config import settings

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

async_engine = create_async_engine(settings.DATABASE_URL, echo=False)


def auto_discover_models() -> List[Type[SQLModel]]:
    """
    ğŸ” ìƒˆë¡œìš´ í†µí•© ëª¨ë¸ ì‚¬ìš©
    """
    models = []

    try:
        # ğŸ¯ ìƒˆë¡œìš´ í†µí•© ëª¨ë¸ë§Œ import
        from src.models import Chunk, Document, Room, TokenUsage, User

        # ğŸ“‹ ëª¨ë¸ í´ë˜ìŠ¤ ëª©ë¡
        model_classes = [
            User,
            Room,
            Document,
            Chunk,
            TokenUsage,
        ]

        # âœ… ìœ íš¨í•œ ëª¨ë¸ë§Œ ë“±ë¡
        for model_class in model_classes:
            if hasattr(model_class, "__tablename__"):
                models.append(model_class)
                print(f"âœ… ëª¨ë¸ ë“±ë¡: {model_class.__name__}")

        print(f"ğŸ¯ ì´ {len(models)}ê°œ ëª¨ë¸ ë“±ë¡ ì™„ë£Œ!")

    except ImportError as e:
        print(f"âŒ ëª¨ë¸ import ì‹¤íŒ¨: {e}")

    return models


async def init_db():
    """
    ğŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

    í…Œì´ë¸” ìƒì„±, ì¸ë±ìŠ¤ ìƒì„±, íŠ¸ë¦¬ê±° ì„¤ì •, ì´ˆê¸° ë°ì´í„° ì‚½ì…ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # ğŸ”„ DB ì—°ê²° ì¬ì‹œë„ ë¡œì§
    max_retries = 2
    retry_interval = 2

    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„ {attempt + 1}/{max_retries}")

            # ğŸ” ëª¨ë¸ ìë™ ë°œê²¬ ë° ë“±ë¡
            discovered_models = auto_discover_models()
            print(f"ğŸ“Š ë°œê²¬ëœ ëª¨ë¸ ìˆ˜: {len(discovered_models)}")

            # ğŸ—ï¸ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
            async with async_engine.begin() as conn:
                # ğŸš€ pgvector í™•ì¥ í™œì„±í™”
                await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
                print("ğŸ”Œ pgvector í™•ì¥ í™œì„±í™” ì™„ë£Œ")

                # ğŸ“‹ ëª¨ë“  í…Œì´ë¸” ìƒì„±
                await conn.run_sync(SQLModel.metadata.create_all)
                print("ğŸ—ï¸ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

                # ğŸš€ HNSW ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
                await conn.execute(
                    text("""
                    CREATE INDEX IF NOT EXISTS chunks_embedding_hnsw_idx 
                    ON chunks 
                    USING hnsw (embedding vector_cosine_ops)
                    WITH (m = 16, ef_construction = 64);
                """)
                )

                print("âš¡ HNSW ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”)")

                # â° updated_at ìë™ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±° í•¨ìˆ˜ ìƒì„±
                await conn.execute(
                    text("""
                CREATE OR REPLACE FUNCTION update_updated_at_column()
                RETURNS TRIGGER AS $$
                BEGIN
                    NEW.updated_at = now();
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
                """)
                )

                # ğŸ“ updated_at ì»¬ëŸ¼ì´ ìˆëŠ” í…Œì´ë¸”ë“¤ ì°¾ê¸°
                table_names = []

                def collect_table_names(metadata):
                    for table in metadata.tables.values():
                        if "updated_at" in table.columns:
                            table_names.append(table.name)

                await conn.run_sync(
                    lambda sync_conn: collect_table_names(SQLModel.metadata)
                )

                # ğŸ”„ ê° í…Œì´ë¸”ì— ëŒ€í•´ íŠ¸ë¦¬ê±° ìƒì„±
                for table_name in table_names:
                    # ğŸ—‘ï¸ ê¸°ì¡´ íŠ¸ë¦¬ê±° ì‚­ì œ
                    await conn.execute(
                        text(
                            f"DROP TRIGGER IF EXISTS update_updated_at_trigger ON {table_name};"
                        )
                    )

                    # â• ìƒˆ íŠ¸ë¦¬ê±° ìƒì„±
                    await conn.execute(
                        text(f"""
                    CREATE TRIGGER update_updated_at_trigger
                    BEFORE UPDATE ON {table_name}
                    FOR EACH ROW
                    EXECUTE FUNCTION update_updated_at_column();
                    """)
                    )

                print(f"â° {len(table_names)}ê°œ í…Œì´ë¸”ì— updated_at íŠ¸ë¦¬ê±° ìƒì„± ì™„ë£Œ")

            # ğŸ¯ ì´ˆê¸° ë°ì´í„° ì‚½ì…
            await insert_initial_data()

            print("ğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì´ˆê¸°í™” ì„±ê³µ!")
            break

        except Exception as e:
            logger.warning(
                f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}"
            )
            if attempt == max_retries - 1:
                logger.error("ğŸš¨ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨!")
                raise
            await asyncio.sleep(retry_interval)


async def insert_initial_data():
    """
    ğŸ“‹ ì´ˆê¸° ë°ì´í„° ì‚½ì…

    ë¬¸ì„œ ìœ í˜•, ê´€ë¦¬ì ê³„ì • ë“±ì„ DBì— ì‚½ì…í•©ë‹ˆë‹¤.
    """
    from src.core.initial_data import insert_all_initial_data

    async_session = async_sessionmaker(
        bind=async_engine,
        class_=AsyncSession,
        expire_on_commit=False,
    )

    async with async_session() as session:
        await insert_all_initial_data(session)


async def get_session() -> AsyncGenerator[AsyncSession, None]:
    """
    ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±

    ë¹„ë™ê¸° ì„¸ì…˜ì„ ìƒì„±í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    async_session = async_sessionmaker(
        bind=async_engine,
        class_=AsyncSession,
        expire_on_commit=False,
    )
    async with async_session() as session:
        yield session
