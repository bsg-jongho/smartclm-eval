import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from langchain_aws import BedrockEmbeddings

logger = logging.getLogger(__name__)


@dataclass
class EmbeddingConfig:
    """ì„ë² ë”© ì„¤ì • í´ë˜ìŠ¤"""

    model_id: str = "amazon.titan-embed-text-v2:0"
    dimensions: int = 1024  # 256, 512, 1024 ì¤‘ ì„ íƒ
    normalize: bool = True
    region_name: str = "ap-northeast-2"


class TitanEmbeddingService:
    """Amazon Titan Text Embeddings V2 + LangChain ì„œë¹„ìŠ¤"""

    def __init__(self, config: Optional[EmbeddingConfig] = None):
        """
        Titan ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            config: ì„ë² ë”© ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.config = config or EmbeddingConfig()

        # LangChain BedrockEmbeddings ì´ˆê¸°í™”
        self.embeddings = BedrockEmbeddings(
            model_id=self.config.model_id,
            region_name=self.config.region_name,
            model_kwargs={
                "dimensions": self.config.dimensions,
                "normalize": self.config.normalize,
            },
        )

        logger.info("Titan ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"  - ëª¨ë¸: {self.config.model_id}")
        logger.info(f"  - ì°¨ì›: {self.config.dimensions}")
        logger.info(f"  - ì •ê·œí™”: {self.config.normalize}")

    async def create_single_embedding(self, text: str) -> List[float]:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            List[float]: ì„ë² ë”© ë²¡í„°
        """
        try:
            logger.debug(f"ë‹¨ì¼ ì„ë² ë”© ìƒì„±: {text[:100]}...")
            embedding = await self.embeddings.aembed_query(text)
            logger.debug(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embedding)}ì°¨ì›")
            return embedding
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise

    async def create_batch_embeddings(
        self, texts: List[str], show_progress: bool = True
    ) -> List[List[float]]:
        """
        ë°°ì¹˜ ì„ë² ë”© ìƒì„± (LangChain ìë™ ìµœì í™”)

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            show_progress: ì§„í–‰ìƒí™© í‘œì‹œ ì—¬ë¶€

        Returns:
            List[List[float]]: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        if not texts:
            return []

        try:
            if show_progress:
                logger.info(f"ë°°ì¹˜ ì„ë² ë”© ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")

            # LangChainì´ ìë™ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬, ì—ëŸ¬ í•¸ë“¤ë§, ì¬ì‹œë„ ìˆ˜í–‰
            embeddings = await self.embeddings.aembed_documents(texts)

            if show_progress:
                logger.info(f"ë°°ì¹˜ ì„ë² ë”© ì™„ë£Œ: {len(embeddings)}ê°œ ë²¡í„° ìƒì„±")

            return embeddings

        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise

    async def embed_chunked_documents(
        self, chunked_documents: List[Dict[str, Any]], content_key: str = "content"
    ) -> List[Dict[str, Any]]:
        """
        ì²­í‚¹ëœ ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•˜ì—¬ ë²¡í„° DB ì €ì¥ìš© í˜•íƒœë¡œ ë³€í™˜
        Parent chunk (ë§¥ë½ìš©)ëŠ” ì„ë² ë”© ì—†ì´, Child chunk (ê²€ìƒ‰ìš©)ë§Œ ì„ë² ë”© ì²˜ë¦¬

        Args:
            chunked_documents: HierarchicalChunkerì˜ create_vector_ready_chunks ê²°ê³¼
            content_key: í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ë“¤ì–´ìˆëŠ” í‚¤ ì´ë¦„

        Returns:
            ì„ë² ë”©ì´ ì¶”ê°€ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ParentëŠ” ì„ë² ë”© ì—†ìŒ, ChildëŠ” ì„ë² ë”© í¬í•¨)
        """
        if not chunked_documents:
            return []

        logger.info(f"ë¬¸ì„œ ì²­í¬ ì„ë² ë”© ì‹œì‘: {len(chunked_documents)}ê°œ ì²­í¬")

        try:
            # ì„ë² ë”© ëŒ€ìƒ ë¶„ë¦¬
            embedding_targets = []
            non_embedding_chunks = []

            for i, doc in enumerate(chunked_documents):
                if doc.get(
                    "is_for_embedding", True
                ):  # Child chunk (ê¸°ë³¸ê°’ Trueë¡œ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
                    embedding_targets.append((i, doc))
                else:  # Parent chunk (ì„ë² ë”© ì—†ì´ ì €ì¥)
                    enhanced_doc = doc.copy()
                    enhanced_doc["embedding"] = None
                    enhanced_doc["embedding_success"] = False
                    enhanced_doc["embedding_metadata"] = {
                        "model_id": self.config.model_id,
                        "reason": "Parent chunk - ì„ë² ë”© ë¶ˆí•„ìš”",
                        "chunk_type": doc.get("chunk_type", "unknown"),
                    }
                    non_embedding_chunks.append((i, enhanced_doc))

            logger.info(
                f"  ğŸ“„ ì„ë² ë”© ëŒ€ìƒ: {len(embedding_targets)}ê°œ (Child chunks + ë‹¨ë… Parent chunks)"
            )
            logger.info(
                f"  ğŸ“‚ ë§¥ë½ ë³´ì¡´: {len(non_embedding_chunks)}ê°œ (ëŒ€í˜• ì„¹ì…˜ Parent chunks)"
            )

            if not embedding_targets:
                logger.warning(
                    "ì„ë² ë”© ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ Parent chunkì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤)"
                )
                return [doc for _, doc in non_embedding_chunks]

            # ì„ë² ë”© ëŒ€ìƒ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            texts = [doc.get(content_key, "") for _, doc in embedding_targets]

            # ë¹ˆ í…ìŠ¤íŠ¸ í•„í„°ë§
            valid_texts = [(i, text) for i, text in enumerate(texts) if text.strip()]

            if not valid_texts:
                logger.warning("ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                return chunked_documents

            # ë°°ì¹˜ ì„ë² ë”© ìƒì„± (Child chunkë§Œ)
            valid_indices, valid_text_list = zip(*valid_texts)
            embeddings = await self.create_batch_embeddings(list(valid_text_list))

            # ê²°ê³¼ ë³‘í•©
            enhanced_documents = [None] * len(chunked_documents)
            embedding_index = 0

            # ì„ë² ë”©ëœ Child chunks ì²˜ë¦¬
            for target_idx, (original_idx, doc) in enumerate(embedding_targets):
                enhanced_doc = doc.copy()

                if target_idx in valid_indices and embedding_index < len(embeddings):
                    enhanced_doc["embedding"] = embeddings[embedding_index]
                    enhanced_doc["embedding_success"] = True
                    enhanced_doc["embedding_metadata"] = {
                        "model_id": self.config.model_id,
                        "dimensions": len(embeddings[embedding_index]),
                        "normalized": self.config.normalize,
                        "chunk_type": doc.get("chunk_type", "child"),
                    }
                    embedding_index += 1
                else:
                    enhanced_doc["embedding"] = None
                    enhanced_doc["embedding_success"] = False
                    enhanced_doc["embedding_error"] = "ë¹ˆ í…ìŠ¤íŠ¸ ë˜ëŠ” ì²˜ë¦¬ ì‹¤íŒ¨"

                enhanced_documents[original_idx] = enhanced_doc

            # ì„ë² ë”© ì—†ëŠ” Parent chunks ì²˜ë¦¬
            for original_idx, enhanced_doc in non_embedding_chunks:
                enhanced_documents[original_idx] = enhanced_doc

            successful_count = sum(
                1
                for doc in enhanced_documents
                if doc and doc.get("embedding_success", False)
            )
            parent_count = sum(
                1
                for doc in enhanced_documents
                if doc and doc.get("chunk_type") == "parent"
            )

            logger.info("ë¬¸ì„œ ì²­í¬ ì„ë² ë”© ì™„ë£Œ:")
            logger.info(
                f"  âœ… ì„ë² ë”© ì„±ê³µ: {successful_count}ê°œ (Child + ë‹¨ë… Parent chunks)"
            )
            logger.info(f"  ğŸ“‚ ë§¥ë½ ë³´ì¡´: {parent_count}ê°œ (Parent chunks)")
            logger.info(f"  ğŸ“Š ì „ì²´: {len([d for d in enhanced_documents if d])}ê°œ")

            return [doc for doc in enhanced_documents if doc is not None]

        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²­í¬ ì„ë² ë”© ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°ì´í„°ì— ì‹¤íŒ¨ ì •ë³´ ì¶”ê°€
            return [
                {
                    **doc,
                    "embedding": None,
                    "embedding_success": False,
                    "embedding_error": str(e),
                }
                for doc in chunked_documents
            ]

    async def test_connection(self) -> Dict[str, Any]:
        """ì„ë² ë”© ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("ì„ë² ë”© ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘")

            # í…ŒìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            test_text = "ì•ˆë…•í•˜ì„¸ìš”. Amazon Titan ì„ë² ë”© ì—°ê²° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
            embedding = await self.create_single_embedding(test_text)

            return {
                "success": True,
                "embedding_length": len(embedding),
                "test_text": test_text,
                "model_info": self.get_model_info(),
            }

        except Exception as e:
            logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "model_info": self.get_model_info(),
            }

    def get_model_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_id": self.config.model_id,
            "dimensions": self.config.dimensions,
            "normalize": self.config.normalize,
            "region": self.config.region_name,
            "max_input_length": 8192,  # Titan V2 ìµœëŒ€ ì…ë ¥ ê¸¸ì´
            "supported_languages": [
                "ko",
                "en",
                "ja",
                "zh",
                "de",
                "fr",
                "es",
                "it",
                "pt",
                "ar",
            ],
            "framework": "langchain-aws",
        }

    def update_config(self, **kwargs) -> None:
        """ì„¤ì • ì—…ë°ì´íŠ¸ (ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•„ìš”)"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                logger.info(f"ì„¤ì • ì—…ë°ì´íŠ¸: {key} = {value}")
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì„¤ì •: {key}")

        logger.warning("ì„¤ì • ë³€ê²½ í›„ì—ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì¬ì´ˆê¸°í™”í•´ì•¼ í•©ë‹ˆë‹¤.")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
titan_embedding_service = TitanEmbeddingService()
